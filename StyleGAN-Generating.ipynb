{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel\n",
        "!pip install torch torchvision\n",
        "!pip install pickle\n",
        "!pip install matplotlib\n",
        "!pip install cv2\n",
        "!pip install numpy\n",
        "!pip install ninja imageio imageio-ffmpeg==0.4.3 scipy==1.10.1"
      ],
      "metadata": {
        "id": "F1vHUh_7C9_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbSuQ1MqB_yV",
        "outputId": "eaead4af-9a4f-4722-dfa3-9e1e66bdc42e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stylegan3' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan3.git\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/stylegan3')\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from stylegan3 import legacy\n",
        "import dnnlib\n",
        "\n",
        "network_pkl = \"/content/drive/MyDrive/ColabNotebooks/stylegan3-t-ffhqu-256x256.pkl\"\n",
        "\n",
        "with open(network_pkl, \"rb\") as f:\n",
        "    data = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gan = data[\"G_ema\"].to(\"cuda\")\n",
        "gan.eval()\n",
        "\n",
        "for param in gan.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "YWTo9gO2KaMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# generate two random faces (256x256)\n",
        "def generate_and_save(seed, filename):\n",
        "    torch.manual_seed(seed)\n",
        "    z = torch.randn((1, 512), device='cuda')\n",
        "    label = torch.zeros([1, gan.c_dim], device='cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img = gan(z, label, truncation_psi=1.0, noise_mode='const')\n",
        "\n",
        "    img = img.squeeze().cpu().numpy()\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    img[img > 1] = 1\n",
        "    img[img < -1] = -1\n",
        "    img = 255 * (img + 1) / 2\n",
        "    img = img.astype(np.uint8)\n",
        "\n",
        "    cv2.imwrite(filename, img[:, :, [2, 1, 0]])\n",
        "\n",
        "# Generate faces\n",
        "generate_and_save(seed=0, filename='face1.png')\n",
        "generate_and_save(seed=1, filename='face2.png')\n",
        "\n",
        "img1 = cv2.cvtColor(cv2.imread('face1.png'), cv2.COLOR_BGR2RGB)\n",
        "img2 = cv2.cvtColor(cv2.imread('face2.png'), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].imshow(img1)\n",
        "axs[0].set_title(\"Face 1 (seed=0)\")\n",
        "axs[0].axis(\"off\")\n",
        "\n",
        "axs[1].imshow(img2)\n",
        "axs[1].set_title(\"Face 2 (seed=1)\")\n",
        "axs[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5uDMgUuDJkP",
        "outputId": "eb205aa3-32a5-42fb-b174-79eef555edcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up PyTorch plugin \"bias_act_plugin\"... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Animation between faces\n",
        "torch.manual_seed(0)\n",
        "z1 = torch.randn((1, gan.z_dim), device='cuda')\n",
        "torch.manual_seed(1)\n",
        "z2 = torch.randn((1, gan.z_dim), device='cuda')\n",
        "label = torch.zeros([1, gan.c_dim], device='cuda')\n",
        "\n",
        "os.makedirs(\"animatedFrames\", exist_ok=True)\n",
        "n_frames = 60\n",
        "\n",
        "for i, alpha in enumerate(tqdm(np.linspace(0, 1, n_frames))):\n",
        "    z = (1 - alpha) * z1 + alpha * z2\n",
        "    with torch.no_grad():\n",
        "        img = gan(z, label, truncation_psi=1.0, noise_mode='const')\n",
        "\n",
        "    img = img.squeeze().cpu().numpy()\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    img = np.clip(img, -1, 1)\n",
        "    img = ((img + 1) * 127.5).astype(np.uint8)\n",
        "\n",
        "    filename = f\"animatedFrames/frame_{i:03d}.png\"\n",
        "    cv2.imwrite(filename, img[:, :, [2, 1, 0]])\n",
        "\n",
        "video_path = 'animatedVideo_256x256.mp4'\n",
        "out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (256, 256))\n",
        "\n",
        "for i in range(n_frames):\n",
        "    frame = cv2.imread(f'animatedFrames/frame_{i:03d}.png')\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n",
        "print(f\"Video saved: {video_path}\")"
      ],
      "metadata": {
        "id": "q5JEGiniLzvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import dlib\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "sys.path.append('/content/drive/MyDrive/ColabNotebooks/PSPNet_simplified/PSPNet')"
      ],
      "metadata": {
        "id": "K5o5KCg5VjDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from options.test_options import TestOptions\n",
        "from models.psp import pSp\n",
        "import cv2\n",
        "from scripts.align_all_parallel import align_face\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alLYRa5gVuBo",
        "outputId": "21a923ae-6ec5-4fb1-f312-ca28469a1a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Animated video from pictures of actors\n",
        "test_opts = Namespace(checkpoint_path=None, couple_outputs=False, data_path='gt_images', exp_dir=None, latent_mask=None, mix_alpha=None, n_images=None, n_outputs_to_generate=5, resize_factors=None, resize_outputs=False, test_batch_size=2, test_workers=2)\n",
        "test_opts.checkpoint_path = '/content/drive/MyDrive/ColabNotebooks/PSPNet_simplified/PSPNet/pretrained_models/psp_ffhq_encode.pt'\n",
        "ckpt = torch.load(test_opts.checkpoint_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts.update(vars(test_opts))\n",
        "opts['output_size'] = 1024\n",
        "\n",
        "opts = Namespace(**opts)\n",
        "\n",
        "\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "#PSPNet + StyleGAN2 network\n",
        "\n",
        "transform = transforms.Compose([\n",
        "\ttransforms.Resize(size=(256, 256)),\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]\n",
        ")\n",
        "\n",
        "\n",
        "predictor = dlib.shape_predictor(\"/content/drive/MyDrive/ColabNotebooks/PSPNet_simplified/PSPNet/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "\n",
        "def get_latent_from_image(image_path, predictor, transform, net):\n",
        "    aligned_image = align_face(filepath=image_path, predictor=predictor)\n",
        "    aligned_image = aligned_image.convert(\"RGB\")\n",
        "    from_im = transform(aligned_image).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_tensor = from_im.float().cuda()\n",
        "        _, latent_vector = net(input_tensor, randomize_noise=False, resize=False, return_latents=True)\n",
        "    return latent_vector\n",
        "\n",
        "img1_path = \"/content/drive/MyDrive/ColabNotebooks/angelinajpeg.jpeg\"\n",
        "img2_path = \"/content/drive/MyDrive/ColabNotebooks/brad.jpg\"\n",
        "\n",
        "latent1 = get_latent_from_image(img1_path, predictor, transform, net)\n",
        "latent2 = get_latent_from_image(img2_path, predictor, transform, net)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwnbX5QHV0BP",
        "outputId": "b1327441-3d65-4f52-bf80-083c0598bc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pSp from checkpoint: /content/drive/MyDrive/ColabNotebooks/PSPNet_simplified/PSPNet/pretrained_models/psp_ffhq_encode.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PSP net creates latent vectors with 18 layers, and stylegan3 expects 16 layers, so I had to go with stylegan2 which PSP was trained on.\n",
        "!wget --content-disposition 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/research/stylegan2/1/files?redirect=true&path=stylegan2-ffhq-1024x1024.pkl' -o 'stylegan2-ffhq-1024x1024.pkl'"
      ],
      "metadata": {
        "id": "YWJhRXi4BM5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/NVlabs/stylegan2.git\n",
        "import sys\n",
        "sys.path.append('/content/stylegan2')\n",
        "\n",
        "import dnnlib\n",
        "import legacy\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "\n",
        "with open(\"/content/stylegan2-ffhq-1024x1024.pkl\", \"rb\") as f:\n",
        "    G = pickle.load(f)['G_ema'].cuda()\n",
        "G.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OyCUvmxCLDb",
        "outputId": "dc95eb45-d945-4a36-dea0-70d9ff00b320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stylegan2' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (synthesis): SynthesisNetwork(\n",
              "    w_dim=512, num_ws=18, img_resolution=1024, img_channels=3, num_fp16_res=4\n",
              "    (b4): SynthesisBlock(\n",
              "      resolution=4, architecture=skip\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=4, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b8): SynthesisBlock(\n",
              "      resolution=8, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=8, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=8, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b16): SynthesisBlock(\n",
              "      resolution=16, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=16, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=16, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b32): SynthesisBlock(\n",
              "      resolution=32, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=32, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=32, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b64): SynthesisBlock(\n",
              "      resolution=64, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=64, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=64, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b128): SynthesisBlock(\n",
              "      resolution=128, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=256, w_dim=512, resolution=128, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=256, out_channels=256, w_dim=512, resolution=128, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=256, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=256, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=256, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b256): SynthesisBlock(\n",
              "      resolution=256, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=256, out_channels=128, w_dim=512, resolution=256, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=256, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=128, out_channels=128, w_dim=512, resolution=256, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=128, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b512): SynthesisBlock(\n",
              "      resolution=512, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=128, out_channels=64, w_dim=512, resolution=512, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=64, out_channels=64, w_dim=512, resolution=512, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=64, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=64, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=64, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b1024): SynthesisBlock(\n",
              "      resolution=1024, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=64, out_channels=32, w_dim=512, resolution=1024, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=64, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=32, out_channels=32, w_dim=512, resolution=1024, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=32, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=32, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=32, activation=linear)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mapping): MappingNetwork(\n",
              "    z_dim=512, c_dim=0, w_dim=512, num_ws=18\n",
              "    (fc0): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc1): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc2): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc3): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc4): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc5): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc6): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc7): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"latent1:\", latent1.shape, latent1.device)\n",
        "print(\"latent2:\", latent2.shape, latent2.device)\n",
        "print(\"First 1-2 values:\", latent1[0, 0, :2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9ZBNSyY9lMr",
        "outputId": "c4ec1235-0bd0-4a78-eeb9-acf0f4c7d66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "latent1: torch.Size([1, 18, 512]) cuda:0\n",
            "latent2: torch.Size([1, 18, 512]) cuda:0\n",
            "First 1-2 values: tensor([-0.6538,  3.2965], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.makedirs(\"animatedActorsFrames\", exist_ok=True)\n",
        "n_frames = 60\n",
        "label = torch.zeros([1, G.c_dim], device='cuda')\n",
        "\n",
        "for i, alpha in enumerate(tqdm(np.linspace(0, 1, n_frames))):\n",
        "    z = (1 - alpha) * latent1 + alpha * latent2\n",
        "    with torch.no_grad():\n",
        "\n",
        "      img = G.synthesis(z, noise_mode='const', input_is_latent=True)\n",
        "\n",
        "    img = img.squeeze().cpu().numpy()\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    img = np.clip(img, -1, 1)\n",
        "    img = ((img + 1) * 127.5).astype(np.uint8)\n",
        "\n",
        "    filename = f\"animatedActorsFrames/frame_{i:03d}.png\"\n",
        "    cv2.imwrite(filename, img[:, :, [2, 1, 0]])\n",
        "\n",
        "video_path = 'animatedActorsVideo.mp4'\n",
        "out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (1024, 1024))\n",
        "\n",
        "for i in range(n_frames):\n",
        "    frame = cv2.imread(f'animatedActorsFrames/frame_{i:03d}.png')\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n",
        "print(f\"Video saved: {video_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1CvV-kZY4MY",
        "outputId": "4c0ef8a5-23b0-4c9e-f1eb-f6d6e12ff821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [00:07<00:00,  7.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video saved: animatedActorsVideo.mp4\n"
          ]
        }
      ]
    }
  ]
}